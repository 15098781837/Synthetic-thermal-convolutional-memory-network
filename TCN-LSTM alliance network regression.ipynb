{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "induced-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from tcn import TCN,tcn_full_summary\n",
    "from tensorflow.keras.layers import Dense,Input,LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import time\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thorough-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "input_train=sio.loadmat('input_train60_1.3.mat')\n",
    "input_real_train=sio.loadmat('input_real_train60_1.3.mat')\n",
    "output_train=sio.loadmat('output_train60_1.3.mat')\n",
    "input_train=input_train['input_train']\n",
    "input_real_train=input_real_train['input_real_train']\n",
    "output_train=output_train['output_train']\n",
    "input_test=sio.loadmat('input_test60_1.3.mat')\n",
    "output_test=sio.loadmat('output_test60_1.3.mat')\n",
    "input_real_test=sio.loadmat('input_real_test60_1.3.mat')\n",
    "input_test=input_test['input_test']\n",
    "output_test=output_test['output_test']\n",
    "input_real_test=input_real_test['input_real_test']\n",
    "input_train=np.transpose(input_train)\n",
    "input_real_train=np.transpose(input_real_train)\n",
    "output_train=np.transpose(output_train)\n",
    "input_test=np.transpose(input_test)\n",
    "output_test=np.transpose(output_test)\n",
    "input_real_test=np.transpose(input_real_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "direct-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize and generate training set and test set\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler1 = MinMaxScaler(feature_range=(0, 1))\n",
    "inputn_train=scaler1.fit_transform(input_train)\n",
    "scaler3 = MinMaxScaler(feature_range=(0, 1))\n",
    "inputn_real_train=scaler3.fit_transform(input_real_train)\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1))\n",
    "outputn_train=scaler2.fit_transform(output_train)\n",
    "inputn_test=scaler1.transform(input_test)\n",
    "inputn_real_test=scaler3.transform(input_real_test)\n",
    "outputn_test=scaler2.transform(output_test)\n",
    "outputn_test.shape\n",
    "XTrain1=np.zeros((12060,20,4))\n",
    "XTrain2=np.zeros((12060,20,4))\n",
    "XTrain3=np.zeros((12060,60,1))\n",
    "YTrain=np.zeros((12060,60))\n",
    "\n",
    "for i in range(12060):\n",
    "    XTrain1[i,:,0]=inputn_train[i:i+20,0]\n",
    "    XTrain1[i,:,1]=inputn_train[i:i+20,1]\n",
    "    XTrain1[i,:,2]=inputn_train[i:i+20,2]\n",
    "    XTrain1[i,:,3]=inputn_train[i:i+20,3]\n",
    "    XTrain2[i,:,0]=inputn_train[i:i+20,0]\n",
    "    XTrain2[i,:,1]=inputn_train[i:i+20,1]\n",
    "    XTrain2[i,:,2]=inputn_train[i:i+20,2]\n",
    "    XTrain2[i,:,3]=inputn_train[i:i+20,3]\n",
    "    XTrain3[i,:]=inputn_real_train[i:i+60]\n",
    "    YTrain[i,:]=outputn_train[i,:]\n",
    "XTest1=np.zeros((12000,20,4))\n",
    "XTest2=np.zeros((12000,20,4))\n",
    "XTest3=np.zeros((12000,60,1))\n",
    "YTest=np.zeros((12000,60))\n",
    "for i in range(12000):\n",
    "    XTest1[i,:,0]=inputn_test[i:i+20,0]\n",
    "    XTest1[i,:,1]=inputn_test[i:i+20,1]\n",
    "    XTest1[i,:,2]=inputn_test[i:i+20,2]\n",
    "    XTest1[i,:,3]=inputn_test[i:i+20,3]\n",
    "    XTest2[i,:,0]=inputn_test[i:i+20,0]\n",
    "    XTest2[i,:,1]=inputn_test[i:i+20,1]\n",
    "    XTest2[i,:,2]=inputn_test[i:i+20,2]\n",
    "    XTest2[i,:,3]=inputn_test[i:i+20,3]\n",
    "    XTest3[i,:]=inputn_real_test[i:i+60]\n",
    "    YTest[i,:]=outputn_test[i,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "miniature-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish network model\n",
    "input1 = Input(batch_shape=(None,20,4), name='input1')\n",
    "input2 = Input(batch_shape=(None,20,4), name='input2')\n",
    "input3=Input(batch_shape=(None,60), name='input3')\n",
    "batch_size, time_steps, input_dim = None, 20, 4\n",
    "tcn_layer1=TCN(input_shape=(time_steps, input_dim),nb_filters=64,\n",
    "    kernel_size=3,dilations=[1,2,4])\n",
    "x=tcn_layer1(input1)\n",
    "x=Dense(60)(x)\n",
    "\n",
    "\n",
    "y=LSTM(64, input_dim=4, input_length=20, return_sequences=True)(input2)\n",
    "y=LSTM(64, input_dim=4, input_length=20, return_sequences=False)(y)\n",
    "y=Dense(128,activation='relu')(y)\n",
    "y=Dense(60)(y)\n",
    "\n",
    "\n",
    "r=keras.layers.concatenate([x,y,input3])\n",
    "r = Dense(64, activation='relu')(r)\n",
    "\n",
    "\n",
    "output = Dense(60, name='main_output')(r)\n",
    "model = Model(inputs=[input1,input2,input3], outputs=[output])\n",
    "def get_lr_metric(optimizer):  # printing the value of the learning rate\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "model.compile(optimizer = optimizer, loss = 'mse', metrics = [lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "authorized-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "235/302 [======================>.......] - ETA: 0s - loss: 0.5473 - lr: 1.0000e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6ce2c13725cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mreduce_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mXTrain1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXTrain2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXTrain3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training network\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    " \n",
    "def scheduler(epoch):\n",
    "    if epoch % 200 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.1)\n",
    "        print(\"lr changed to {}\".format(lr * 0.1))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    " \n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "start=time.process_time()\n",
    "history=model.fit([XTrain1,XTrain2,XTrain3], YTrain, epochs=300, validation_split=0.2,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss\n",
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']         \n",
    "val_loss = history.history['val_loss'] \n",
    "epochs = range(1,len(loss)+1)\n",
    "plt.figure()   \n",
    "plt.plot(epochs,val_loss,'b',label='Vaildation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "YPred0=model.predict([XTrain1,XTrain2,XTrain3])\n",
    "YPred=model.predict([XTest1,XTest2,XTest3])\n",
    "YPred0=scaler2.inverse_transform(YPred0)\n",
    "YPred=scaler2.inverse_transform(YPred)\n",
    "YTest=scaler2.inverse_transform(YTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(YTest[10:10000,:],YPred[10:10000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "from scipy.io import savemat\n",
    "savemat('TCN_LSTM_regression_loss.mat',{'TCN_LSTM_val_loss':val_loss})\n",
    "savemat('LSTM_TCN_YPred_60_1.3.mat',{'TCN_LSTM_YPred':YPred})\n",
    "savemat('LSTM_TCN_YPred0_60_1.3.mat',{'LSTM_TCN_YPred0_60_1.3.1':YPred0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-laptop",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
